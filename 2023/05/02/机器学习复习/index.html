<!DOCTYPE html>
<html lang="zh-CN">
<head>

    <!--自定义看板娘-->
  <script src="https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script>
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"/>

  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.1.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/dragon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/dragon.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="baidu-site-verification" content="6EMwG3w0uT">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-center-circle.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"decxlr.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":300,"display":"post","padding":5,"offset":5,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":true,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="机器学习选择题 10 * 3 &#x3D; 30填空题 5 * 2 &#x3D; 10简答题：5 * 6 &#x3D; 30综合题 2 * 15 &#x3D; 30">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习复习">
<meta property="og:url" content="https://decxlr.github.io/2023/05/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0/index.html">
<meta property="og:site_name" content="君不见の博客">
<meta property="og:description" content="机器学习选择题 10 * 3 &#x3D; 30填空题 5 * 2 &#x3D; 10简答题：5 * 6 &#x3D; 30综合题 2 * 15 &#x3D; 30">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682735602911.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682736699197.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682736720931.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682736750180.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682736771172.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682736786724.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682738763530.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682738784113.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682741360641.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682741397256.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682741419202.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682741545863.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682742439840.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682742539598.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682742865494.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682742885050.png">
<meta property="og:image" content="https://decxlr.github.io/%5Cassets%5C1682742923208.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682743586940.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682743616107.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682743641131.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682747519250.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682747568955.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682747610233.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682747787015.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682747807634.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682747825725.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682747868490.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682747890589.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682782468118.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682782549230.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682782579185.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682782613889.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682782646956.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682782704932.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682782731597.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682782764550.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682782785821.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682782809506.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682786191204.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682786211342.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682786315174.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682786459898.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682786483259.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682786508798.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682786578895.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682786666961.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682787858250.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682787882142.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682787900217.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682787941530.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682787964009.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682787985273.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682882868088.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682882903456.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682882926387.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682882989456.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682883078606.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682883092653.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682883272170.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682883319146.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682883377475.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682883414736.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682883446921.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682883460482.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682883617979.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682883640612.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682883706216.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682928842769.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682928860785.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682929110883.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682929131198.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682929169693.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682929508688.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682929782332.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682929888771.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682929907326.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682929920706.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682929939155.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682929964521.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682930072738.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682930117888.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682930143941.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682930183582.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682930196112.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1682930206595.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038285710.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038298601.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038344132.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038375526.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038477113.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038510242.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038539836.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038572159.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038586557.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038788172.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038801431.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038822807.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038845703.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038863986.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038981652.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683038998968.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683039040790.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683039059299.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683039079007.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683039101323.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683039127439.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683039153432.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683039169732.png">
<meta property="og:image" content="https://decxlr.github.io/assets%5C1683039203984.png">
<meta property="article:published_time" content="2023-05-02T14:56:18.000Z">
<meta property="article:modified_time" content="2023-05-08T14:21:34.374Z">
<meta property="article:author" content="君不见">
<meta property="article:tag" content="Note">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://decxlr.github.io/assets%5C1682735602911.png">

<link rel="canonical" href="https://decxlr.github.io/2023/05/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>机器学习复习 | 君不见の博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

  
<link rel="alternate" href="/atom.xml" title="君不见の博客" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage">

  <script type="text/javascript" src="/js/dytitle.js"></script>

  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">君不见の博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">记录生活中的点点滴滴</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">30</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">14</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">55</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://decxlr.github.io/2023/05/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/tsy.png">
      <meta itemprop="name" content="君不见">
      <meta itemprop="description" content="君不见，黄河之水天上来，奔流到海不复回。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="君不见の博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习复习
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-05-02 22:56:18" itemprop="dateCreated datePublished" datetime="2023-05-02T22:56:18+08:00">2023-05-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-05-08 22:21:34" itemprop="dateModified" datetime="2023-05-08T22:21:34+08:00">2023-05-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Changyan：</span>
    
    
      <a title="changyan" href="/2023/05/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0/#SOHUCS" itemprop="discussionUrl">
        <span id="changyan_count_unit" class="post-comments-count hc-comment-count" data-xid="2023/05/02/机器学习复习/" itemprop="commentCount"></span>
      </a>
    
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>机器学习<br>选择题 10 * 3 &#x3D; 30<br>填空题 5 * 2 &#x3D; 10<br>简答题：5 * 6 &#x3D; 30<br>综合题 2 * 15 &#x3D; 30</p>
<h2 id="机器学习-引言"><a href="#机器学习-引言" class="headerlink" title="机器学习-引言"></a>机器学习-引言</h2><ol>
<li><strong>机器学习的类型</strong> 监督学习、无监督学习的分类等<ul>
<li>监督学习：</li>
<li>无监督学习</li>
</ul>
</li>
<li>机器学习的模型</li>
<li>损失函数</li>
</ol>
<h3 id="机器学习的类型-监督学习"><a href="#机器学习的类型-监督学习" class="headerlink" title="机器学习的类型-监督学习"></a>机器学习的类型-监督学习</h3><p>✓ 分类（Classification） </p>
<p>​	✓ 身高1.65m，体重100kg的男人肥胖吗？ </p>
<p>​	✓ 根据肿瘤的体积、患者的年龄来判断良性或恶性？ </p>
<p>✓ 回归（Regression、Prediction） </p>
<p>​	✓ 如何预测上海浦东的房价？ </p>
<p>​	✓ 未来的股票市场走向？</p>
<h3 id="机器学习的类型-无监督学习"><a href="#机器学习的类型-无监督学习" class="headerlink" title="机器学习的类型-无监督学习"></a>机器学习的类型-无监督学习</h3><p>✓ 聚类（Clustering） </p>
<p>​	✓ 如何将教室里的学生按爱好、身高划分为5类？ </p>
<p>✓ 降维（ Dimensionality Reduction ） </p>
<p>​	✓ 如何将将原高维空间中的数据点映射到低维度的空间中？</p>
<h3 id="机器学习的类型-强化学习"><a href="#机器学习的类型-强化学习" class="headerlink" title="机器学习的类型-强化学习"></a>机器学习的类型-强化学习</h3><p>✓ 强化学习（Reinforcement Learning） </p>
<p>​	✓ 用于描述和解决智能体（agent）在与环境的交互过程中通过学习策略以达成回报最大化或实现特定目标的问题 。</p>
<h3 id="机器学习的概念-模型"><a href="#机器学习的概念-模型" class="headerlink" title="机器学习的概念-模型"></a>机器学习的概念-模型</h3><p>机器学习首先要考虑使用什么样的模型。 </p>
<p>模型的类别，大致有两种：一是概率模型(Probabilistic Model)和非概率模型(Non-Probabilistic Model)。 </p>
<p>在监督学习中，概率模型可被表示为𝑃(𝑦|𝑥)，非概率模型则为𝑦 &#x3D; 𝑓(𝑥)。 </p>
<p>其中，𝑥是输入，𝑦是输出。 </p>
<p>在无监督学习中，概率模型可被表示为𝑃(𝑧|𝑥)，非概率模型则为𝑧 &#x3D; 𝑓(𝑥)。 </p>
<p>其中，𝑥是输入，𝑧是输出。</p>
<p>决策树、朴素贝叶斯、隐马尔科夫模型、高斯混合模型属于<strong>概率模型</strong>。 </p>
<p>感知机、支持向量机、KNN(𝑘近邻法)、AdaBoost(集成学习)、K-means(聚类 )以及神经网络均属于<strong>非概率模型</strong>。 </p>
<p>对于非概率模型而言，可按照判别函数线性与否分成线性模型与非线性模型。 </p>
<p>感知机、线性支持向量机、KNN、K-means是<strong>线性模型</strong>。 </p>
<p>核支持向量机、AdaBoost、神经网络属于<strong>非线性模型</strong>。</p>
<h3 id="机器学习的概念-损失函数"><a href="#机器学习的概念-损失函数" class="headerlink" title="机器学习的概念-损失函数"></a>机器学习的概念-损失函数</h3><ol>
<li>0-1损失函数(0-1 Loss Function)</li>
</ol>
<p><img src="/assets%5C1682735602911.png" alt="1682735602911"></p>
<ol start="2">
<li>平方损失函数(Quadratic Loss Function)</li>
</ol>
<p> <img src="/assets%5C1682736699197.png" alt="1682736699197"></p>
<ol start="3">
<li>绝对损失函数(Absolute Loss Function)</li>
</ol>
<p><img src="/assets%5C1682736720931.png" alt="1682736720931"></p>
<ol start="4">
<li>对数损失函数(Logarithmic Loss Function)</li>
</ol>
<p><img src="/assets%5C1682736750180.png" alt="1682736750180"></p>
<p>根据上述损失函数模型，我们可知，损失函数值越小，模型性能越好。给定一个数据集，我们将训练数据集的平均损失称为经验风险。基于经验风险最小化原则，可构建全局损失函数求解最优 化问题： </p>
<p><img src="/assets%5C1682736771172.png" alt="1682736771172"></p>
<p>当样本数量足够大时，根据大数定理，经验风险会近似于模型的期望风险。此时，经验风险最小化能确保有好的学习性能。然而，当样本数量不足时，单单利用经验风险最小化可能会导致 “过拟合”的问题。 </p>
<p>为此，我们再原有基础上加上用于控制模型复杂度的正则项(Regularizer)，得到结构最小化准 则。具体定义是： </p>
<p><img src="/assets%5C1682736786724.png" alt="1682736786724"></p>
<p>其中，𝐽(𝑓)代表对模型复杂度的惩罚。模型越复杂，𝐽(𝑓)越大，模型越简单，𝐽(𝑓)就越小。𝜆是 一个正的常数，也叫正则化系数，用于平衡经验风险和模型复杂度。 </p>
<p>一般来说，结构风险小的模型需要经验风险和模型复杂度同时小，因此对训练数据和测试数据 都能有较好的拟合</p>
<h2 id="机器学习-回归"><a href="#机器学习-回归" class="headerlink" title="机器学习-回归"></a>机器学习-回归</h2><ol>
<li>最小二乘法</li>
<li>梯度下降（学习率）<ul>
<li>学习率小：局部最优</li>
</ul>
</li>
<li>归一化&#x2F;标准化</li>
<li>正则化：分析过拟合、欠拟合<ul>
<li>L1正则化</li>
<li>L2正则化</li>
</ul>
</li>
<li>不管评价指标</li>
</ol>
<h3 id="线性回归-最小二乘法-LSM"><a href="#线性回归-最小二乘法-LSM" class="headerlink" title="线性回归-最小二乘法(LSM)"></a>线性回归-最小二乘法(LSM)</h3><p><img src="/assets%5C1682738763530.png" alt="1682738763530"></p>
<p><img src="/assets%5C1682738784113.png" alt="1682738784113"></p>
<h3 id="梯度下降的三种形式"><a href="#梯度下降的三种形式" class="headerlink" title="梯度下降的三种形式"></a>梯度下降的三种形式</h3><h4 id="批量梯度下降"><a href="#批量梯度下降" class="headerlink" title="批量梯度下降"></a>批量梯度下降</h4><p>Batch Gradient Descent,BGD</p>
<p>梯度下降的每一步中，都用到了<strong>所有</strong>的训练样本 </p>
<p><img src="/assets%5C1682741360641.png" alt="1682741360641"></p>
<h4 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h4><p>Stochastic Gradient Descent,SGD</p>
<p>梯度下降的每一步中，用到一个样本，在每一次计算之后便更新参数 ，而不需要首先将所有的训练集求和 </p>
<p><img src="/assets%5C1682741397256.png" alt="1682741397256"></p>
<p><img src="/assets%5C1682741419202.png" alt="1682741419202"></p>
<h4 id="小批量梯度下降"><a href="#小批量梯度下降" class="headerlink" title="小批量梯度下降"></a>小批量梯度下降</h4><p>Mini-Batch Gradient Descent,MBGD</p>
<p>梯度下降的每一步中，用到了<strong>一定批量</strong>的训练样本</p>
<p><img src="/assets%5C1682741545863.png" alt="1682741545863"></p>
<h3 id="梯度下降与最小二乘法比较"><a href="#梯度下降与最小二乘法比较" class="headerlink" title="梯度下降与最小二乘法比较"></a>梯度下降与最小二乘法比较</h3><h4 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h4><p>需要选择学习率𝛼，需要多次迭代，当特征数量𝑛大时也能较 好适用，适用于各种类型的模型。 </p>
<h4 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h4><p>不需要选择学习率𝛼，一次计算得出，需要计算 (𝑋 ^𝑇)𝑋^(−1) ，如果特征数量𝑛较大则运算代价大，因为矩阵逆的计算时间复杂度为 𝑂(𝑛^3 )，通常来说当𝑛小于10000 时还是可以接受的，只适用于线性模型 ，不适合逻辑回归模型等其他模型</p>
<h3 id="数据归一化-x2F-标准化"><a href="#数据归一化-x2F-标准化" class="headerlink" title="数据归一化&#x2F;标准化"></a>数据归一化&#x2F;标准化</h3><p>为什么要标准化&#x2F;归一化？ </p>
<h4 id="提升模型精度"><a href="#提升模型精度" class="headerlink" title="提升模型精度"></a>提升模型精度</h4><p>不同维度之间的 特征在数值上有一定比较性，可 以大大提高分类器的准确性。 </p>
<h4 id="加速模型收敛"><a href="#加速模型收敛" class="headerlink" title="加速模型收敛"></a>加速模型收敛</h4><p>最优解的寻优过 程明显会变得平缓，更容易正确 的收敛到最优解。</p>
<p><img src="/assets%5C1682742439840.png" alt="1682742439840"></p>
<p><strong>需要做数据归一化&#x2F;标准化</strong> </p>
<p>线性模型，如基于距离度量的模型包括KNN(K近邻)、K-means聚类、 感知机和SVM。另外，线性回归类的几个模型一般情况下也是需要做数 据归一化&#x2F;标准化处理的。 </p>
<p><strong>不需要做数据归一化&#x2F;标准化</strong> </p>
<p>决策树、基于决策树的Boosting和Bagging等集成学习模型对于特征取 值大小并不敏感，如随机森林、XGBoost、LightGBM等树模型，以及 朴素贝叶斯，以上这些模型一般不需要做数据归一化&#x2F;标准化处理。</p>
<h3 id="过拟合和欠拟合"><a href="#过拟合和欠拟合" class="headerlink" title="过拟合和欠拟合"></a>过拟合和欠拟合</h3><p><img src="/assets%5C1682742539598.png" alt="1682742539598"></p>
<h4 id="过拟合的处理"><a href="#过拟合的处理" class="headerlink" title="过拟合的处理"></a>过拟合的处理</h4><p>1.获得更多的训练数据 </p>
<p>使用更多的训练数据是解决过拟合问题最有效的手段，因为更多的样本能够让模型学习到更多更有效的特征，减小噪声的影响。 </p>
<p>2.降维 </p>
<p>即丢弃一些不能帮助我们正确预测的特征。可以是手工选择保留哪些特征，或者使用一些模型选择的算法来帮忙（例如PCA）。 </p>
<p>3.正则化 </p>
<p>正则化(regularization)的技术，保留所有的特征，但是减少参数的大小（magnitude），它可以改善或者减少过拟合问题。 </p>
<p>4.集成学习方法 </p>
<p>集成学习是把多个模型集成在一起，来降低单一模型的过拟合风险</p>
<h4 id="欠拟合的处理"><a href="#欠拟合的处理" class="headerlink" title="欠拟合的处理"></a>欠拟合的处理</h4><p>1.添加新特征 </p>
<p>当特征不足或者现有特征与样本标签的相关性不强时，模型容易出现欠拟合。通过挖掘组合特征等新的特征，往往能够取得更好的效果。 </p>
<p>2.增加模型复杂度 </p>
<p>简单模型的学习能力较差，通过增加模型的复杂度可以使模型拥有更强的拟合能力。例如，在线性模型中添加高次项，在神经网络模型中增加网络层数或神经元个数等。 </p>
<p>3.减小正则化系数 </p>
<p>正则化是用来防止过拟合的，但当模型出现欠拟合现象时，则需要有针对性地减小正则化系数</p>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><h4 id="𝐋𝟏正则化"><a href="#𝐋𝟏正则化" class="headerlink" title="𝐋𝟏正则化"></a>𝐋𝟏正则化</h4><p><img src="/assets%5C1682742865494.png" alt="1682742865494"></p>
<h4 id="𝐋2正则化"><a href="#𝐋2正则化" class="headerlink" title="𝐋2正则化"></a>𝐋2正则化</h4><p><img src="/assets%5C1682742885050.png" alt="1682742885050"></p>
<h4 id="正则化-1"><a href="#正则化-1" class="headerlink" title="正则化"></a>正则化</h4><p><img src="/%5Cassets%5C1682742923208.png" alt="1682742923208"></p>
<p>图上面中的蓝色轮廓线是没有正则化损失函数的等高线，中心的蓝色点为最优解，左图、右图分别为L1、L2正则化给出的限制。 </p>
<p>可以看到在正则化的限制之下, 𝐋2正则化给出的最优解w*是使解更加靠近原点,也就是说𝐋𝟐正则化能降低参数范数的总和。 </p>
<p>𝐋𝟏正则化给出的最优解w*是使解更加靠近某些轴,而其它的轴则为0,所以𝐋𝟏正则化能使得到的参数稀疏化。</p>
<h2 id="机器学习-逻辑回归"><a href="#机器学习-逻辑回归" class="headerlink" title="机器学习-逻辑回归"></a>机器学习-逻辑回归</h2><ol>
<li>sigmoid函数：表达式 逻辑回归的激活函数</li>
<li>损失函数：交叉熵</li>
</ol>
<h3 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h3><p><img src="/assets%5C1682743586940.png" alt="1682743586940"></p>
<p><img src="/assets%5C1682743616107.png" alt="1682743616107"></p>
<p><img src="/assets%5C1682743641131.png" alt="1682743641131"></p>
<h3 id="逻辑回归求解"><a href="#逻辑回归求解" class="headerlink" title="逻辑回归求解"></a>逻辑回归求解</h3><p><img src="/assets%5C1682747519250.png" alt="1682747519250"></p>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p><img src="/assets%5C1682747568955.png" alt="1682747568955"></p>
<h4 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h4><p><img src="/assets%5C1682747610233.png" alt="1682747610233"></p>
<h4 id="逻辑回归求解-1"><a href="#逻辑回归求解-1" class="headerlink" title="逻辑回归求解"></a>逻辑回归求解</h4><p><img src="/assets%5C1682747787015.png" alt="1682747787015"></p>
<p><img src="/assets%5C1682747807634.png" alt="1682747807634"></p>
<p><img src="/assets%5C1682747825725.png" alt="1682747825725"></p>
<p><img src="/assets%5C1682747868490.png" alt="1682747868490"></p>
<p><img src="/assets%5C1682747890589.png" alt="1682747890589"></p>
<h2 id="机器学习-朴素贝叶斯"><a href="#机器学习-朴素贝叶斯" class="headerlink" title="机器学习-朴素贝叶斯"></a>机器学习-朴素贝叶斯</h2><ol>
<li>朴素贝叶斯原理</li>
</ol>
<h3 id="朴素贝叶斯原理"><a href="#朴素贝叶斯原理" class="headerlink" title="朴素贝叶斯原理"></a>朴素贝叶斯原理</h3><h4 id="判别模型和生成模型"><a href="#判别模型和生成模型" class="headerlink" title="判别模型和生成模型"></a>判别模型和生成模型</h4><p>监督学习方法又分 </p>
<p><strong>生成方法</strong>（Generative approach）和<strong>判别方法</strong>（Discriminative approach） </p>
<p>所学到的模型分别称为 </p>
<p><strong>生成模型</strong>（Generative Model）和<strong>判别模型</strong>（Discriminative Model)。</p>
<table>
<thead>
<tr>
<th>判别模型（Discriminative Model)</th>
<th>生成模型（Generative Model）</th>
</tr>
</thead>
<tbody><tr>
<td>由数据直接学习决策函数Y&#x3D;f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型。基本思想是有限样本条件下建立判别函数，不考虑样本的产生模型，直接研究预测模型。 即：直接估计𝑃(𝑌|𝑋)</td>
<td>由训练数据学习联合概率分布 𝑃(𝑋, 𝑌)，然后求得后验概率分布𝑃(𝑌|𝑋)。具体来说，利用训练数据学习𝑃(𝑋|𝑌)和𝑃(𝑌)的估计，得到联合概率分布： 𝑃(𝑋, 𝑌)＝𝑃(𝑌)𝑃(𝑋|𝑌)，再利用它进行分类。 即：估计𝑃(𝑋|𝑌) 然后推导𝑃(𝑌|𝑋)</td>
</tr>
<tr>
<td>线性回归、逻辑回归、感知机、决策树、支持向量机……</td>
<td>朴素贝叶斯、HMM、深度信念网络(DBN)……</td>
</tr>
</tbody></table>
<ol>
<li>朴素贝叶斯法是典型的生成学习方法。</li>
</ol>
<p>生成方法由训练数据学习联合概率分布 𝑃(𝑋, 𝑌)，然后求得后验概率分 布𝑃(𝑌|𝑋)。具体来说，利用训练数据学习𝑃(𝑋|𝑌)和𝑃(𝑌)的估计，得到 联合概率分布： </p>
<p>𝑃(𝑋, 𝑌)＝𝑃(𝑌)𝑃(𝑋|𝑌) </p>
<p>概率估计方法可以是极大似然估计或贝叶斯估计。</p>
<ol start="2">
<li>朴素贝叶斯法的基本假设是条件独立性。</li>
</ol>
<p><img src="/assets%5C1682782468118.png" alt="1682782468118"></p>
<p>ck代表类别，k代表类别个数。 </p>
<p>这是一个较强的假设。由于这一假设，模型包含的条件概率的数量大为减少，朴素贝叶斯法的学习与预测大为简化。因而朴素贝叶斯法高效，且易于实现。其缺点是分类的性能不一定很高。</p>
<p>朴素贝叶斯法利用贝叶斯定理与学到的联合概率模型进行分类预测 </p>
<ol start="3">
<li><p>我们要求的是𝑃(𝑌|𝑋)，根据生成模型定义我们可以求𝑃(𝑋, 𝑌)和𝑃(𝑌)假设中的 特征是条件独立的。这个称作朴素贝叶斯假设。 形式化表示为，（如果给定 𝑍的情况下，𝑋和𝑌条件独立）： </p>
<p>𝑃(𝑋|𝑍) &#x3D; 𝑃(𝑋|𝑌, 𝑍)</p>
</li>
</ol>
<p>也可以表示为： </p>
<p>​	𝑃(𝑋, 𝑌|𝑍) &#x3D; 𝑃(𝑋|𝑍)𝑃(𝑌|𝑍)</p>
<p>用于文本分类的朴素贝叶斯模型，这个模型称作多值伯努利事件模型。 </p>
<p>在这个模型中，我们首先随机选定了邮件的类型𝑝(𝑦)，然后一个人翻阅词典的所有词，随机决定一个词是否出现依照概率𝑝(𝑥 (1) |𝑦)，出现标示为1，否则标示为0 。假设有50000个单词，那么这封邮件的概率可以表示为：</p>
<p><img src="/assets%5C1682782549230.png" alt="1682782549230"></p>
<h4 id="独立性"><a href="#独立性" class="headerlink" title="独立性"></a>独立性</h4><p>将输入𝑥分到后验概率最大的类𝑦。 </p>
<p><img src="/assets%5C1682782579185.png" alt="1682782579185"></p>
<p>后验概率最大等价于0-1损失函数时的期望风险最小化。</p>
<p><img src="/assets%5C1682782613889.png" alt="1682782613889"></p>
<p>朴素贝叶斯法对<strong>条件概率分布作了条件独立性的假设</strong>。由于这是一个较强的假设，朴素贝叶斯法也由此得名。具体地，条件独立性假设是： </p>
<p><img src="/assets%5C1682782646956.png" alt="1682782646956"></p>
<p>朴素贝叶斯法分类时，对给定的输入𝑥，通过学习到的模型计算 </p>
<p>后验概率分布𝑃(𝑌 &#x3D; 𝑐𝑘| 𝑋 &#x3D; 𝑥 )，将后验概率最大的类作为𝑥的类输 出。根据贝叶斯定理:</p>
<p><img src="/assets%5C1682782704932.png" alt="1682782704932"></p>
<p>可以计算后验概率 </p>
<p><img src="/assets%5C1682782731597.png" alt="1682782731597"></p>
<p>将式(1)代入公式(2)，可以得到 </p>
<p><img src="/assets%5C1682782764550.png" alt="1682782764550"></p>
<p>贝叶斯分类器可以表示为： </p>
<p><img src="/assets%5C1682782785821.png" alt="1682782785821"></p>
<p>上式中分母中𝑐𝑘都是一样的，即不会对结果产生影响，即</p>
<p><img src="/assets%5C1682782809506.png" alt="1682782809506"></p>
<h2 id="机器学习-决策树"><a href="#机器学习-决策树" class="headerlink" title="机器学习-决策树"></a>机器学习-决策树</h2><ul>
<li>决策树的构造方式：</li>
<li>ID3<ul>
<li>信息熵、条件熵、缺点、有点</li>
</ul>
</li>
<li>C4.5<ul>
<li>剪枝</li>
</ul>
</li>
</ul>
<h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><p><img src="/assets%5C1682786191204.png" alt="1682786191204"></p>
<p><img src="/assets%5C1682786211342.png" alt="1682786211342"></p>
<h3 id="决策树的特点"><a href="#决策树的特点" class="headerlink" title="决策树的特点"></a>决策树的特点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>⚫ 推理过程容易理解，计算简单，可解释性强。 </p>
<p>⚫ 比较适合处理有缺失属性的样本。 </p>
<p>⚫ 可自动忽略目标变量没有贡献的属性变量，也为判断属性变量的重要性，减少变量的数目提供参考。 </p>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p>⚫ 容易造成过拟合，需要采用剪枝操作。 </p>
<p>⚫ 忽略了数据之间的相关性。 </p>
<p>⚫ 对于各类别样本数量不一致的数据，信息增益会偏向于那些更多数值的特征。</p>
<h3 id="决策树的三种基本类型"><a href="#决策树的三种基本类型" class="headerlink" title="决策树的三种基本类型"></a>决策树的三种基本类型</h3><p>建立决策树的关键，即在当前状态下选择哪个属性作为分类依据。根据不同 的目标函数 ， 建立决策树主要有一下三种算法： ID3(Iterative Dichotomiser)、C4.5、CART(Classification And Regression Tree)。</p>
<p><img src="/assets%5C1682786315174.png" alt="1682786315174"></p>
<h3 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h3><p>⚫ ID3 算法最早是由罗斯昆（J. Ross Quinlan）于1975年提出的一种决策树构建算法，算法的核心是“<strong>信息熵</strong>” ，期望信息越小，信息熵越大，样本纯度越低。。 </p>
<p>⚫ ID3 算法是以信息论为基础，以<strong>信息增益</strong>为衡量标准，从而实现对数据的归纳分类。 </p>
<p>⚫ ID3 算法计算每个属性的信息增益，并选取具有最高增益的属性作为给定的测试属性。</p>
<h4 id="其大致步骤为："><a href="#其大致步骤为：" class="headerlink" title="其大致步骤为："></a>其大致步骤为：</h4><ol>
<li><p>初始化特征集合和数据集合； </p>
</li>
<li><p>计算数据集合信息熵和所有特征的条件熵，选择信息增益最大的特征作为当 前决策节点； </p>
</li>
<li><p>更新数据集合和特征集合（删除上一步使用的特征，并按照特征值来划分不同分支的数据集合）； </p>
</li>
<li><p>重复 2，3 两步，若子集值包含单一特征，则为分支叶子节点。</p>
</li>
</ol>
<h4 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h4><p><img src="/assets%5C1682786459898.png" alt="1682786459898"></p>
<p><img src="/assets%5C1682786483259.png" alt="1682786483259"></p>
<h4 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h4><p><img src="/assets%5C1682786508798.png" alt="1682786508798"></p>
<h4 id="信息增益（）"><a href="#信息增益（）" class="headerlink" title="信息增益（）"></a>信息增益（）</h4><p><img src="/assets%5C1682786578895.png" alt="1682786578895"></p>
<h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><p>ID3 没有剪枝策略，容易过拟合； </p>
<p>信息增益准则对可取值数目较多的特征有所偏好，类似“编号”的特征其信息增益接近于 1； </p>
<p>只能用于处理离散分布的特征； </p>
<p>没有考虑缺失值。</p>
<h3 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法"></a>C4.5算法</h3><p>C4.5 算法是 Ross 对 ID3 算法的改进。 </p>
<p>⚫ 用<strong>信息增益率</strong>来选择属性。ID3选择属性用的是子树的信息增益， 而C4.5用的是<strong>信息增益率</strong>。 </p>
<p>⚫ 在决策树构造过程中进行<strong>剪枝</strong>。 </p>
<p>⚫ 对<strong>非离散数据</strong>也能处理。 </p>
<p>⚫ 能够对<strong>不完整数据</strong>进行处理。</p>
<h4 id="信息增益率（）"><a href="#信息增益率（）" class="headerlink" title="信息增益率（）"></a>信息增益率（）</h4><p><img src="/assets%5C1682786666961.png" alt="1682786666961"></p>
<h4 id="C4-5的剪枝"><a href="#C4-5的剪枝" class="headerlink" title="C4.5的剪枝"></a>C4.5的剪枝</h4><p>过拟合的原因： </p>
<p>为了尽可能正确分类训练样本，节点的划分过程会不断重复直到不能再分，这样就可能对训练样本学习的“太好”了，把训练样本的一些特点当做所有数据都具有的一般性质，从而导致过拟合。 </p>
<p>通过剪枝处理去掉一些分支来降低过拟合的风险。 </p>
<p>剪枝的基本策略有“预剪枝”（prepruning）和“后剪枝”（post-pruning）</p>
<h4 id="预剪枝（prepruning）"><a href="#预剪枝（prepruning）" class="headerlink" title="预剪枝（prepruning）"></a>预剪枝（prepruning）</h4><p>预剪枝不仅可以降低过拟合的风险而且还可以减少训练时间，但另一方面它是基于“贪心” 策略，会带来欠拟合风险。 </p>
<p><img src="/assets%5C1682787858250.png" alt="1682787858250"></p>
<p><img src="/assets%5C1682787882142.png" alt="1682787882142"></p>
<p><img src="/assets%5C1682787900217.png" alt="1682787900217"></p>
<h4 id="后剪枝"><a href="#后剪枝" class="headerlink" title="后剪枝"></a>后剪枝</h4><p>在已经生成的决策树上进行剪枝，从而 得到简化版的剪枝决策树。 </p>
<p>后剪枝决策树通常比预剪枝决策树保留了更多的分支。一般情况下，后剪枝的 欠拟合风险更小，泛化性能往往优于预剪枝决策树。</p>
<p><img src="/assets%5C1682787941530.png" alt="1682787941530"></p>
<p><img src="/assets%5C1682787964009.png" alt="1682787964009"></p>
<p><img src="/assets%5C1682787985273.png" alt="1682787985273"></p>
<h4 id="C4-5的缺点"><a href="#C4-5的缺点" class="headerlink" title="C4.5的缺点"></a>C4.5的缺点</h4><p>• 剪枝策略可以再优化； </p>
<p>• C4.5 用的是多叉树，用二叉树效率更高； </p>
<p>• C4.5 只能用于分类； </p>
<p>• C4.5 使用的熵模型拥有大量耗时的对数运算，连续值还有排序运算； </p>
<p>• C4.5 在构造树的过程中，对数值属性值需要按照其大小进行排序，从中 选择一个分割点，所以只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时，程序无法运行。</p>
<h2 id="机器学习-集成学习"><a href="#机器学习-集成学习" class="headerlink" title="机器学习-集成学习"></a>机器学习-集成学习</h2><ol>
<li>什么是集成学习</li>
<li>集成学习的分类<ul>
<li>Bagging（<strong>随机森林</strong>）</li>
<li>Boosting</li>
<li>Stacking</li>
</ul>
</li>
</ol>
<h3 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h3><h4 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h4><p><img src="/assets%5C1682882868088.png" alt="1682882868088"></p>
<h4 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h4><p><img src="/assets%5C1682882903456.png" alt="1682882903456"></p>
<h4 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h4><p><img src="/assets%5C1682882926387.png" alt="1682882926387"></p>
<h4 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h4><p>Random Forest（随机森林） </p>
<p>用随机的方式建立一个森林。随机森林算法由很多决策树组成，每一棵决策树之间没有关联。建立完森林后，当有新样本进入时，每棵决策树都会分别进行判断，然后基于投票法给出分类结果。 </p>
<p>优点 </p>
<ol>
<li>在数据集上表现良好，相对于其他算法有较大的优势 </li>
<li>易于并行化，在大数据集上有很大的优势； </li>
<li>能够处理高维度数据，不用做特征选择。</li>
</ol>
<p><img src="/assets%5C1682882989456.png" alt="1682882989456"></p>
<h3 id="AdaBoost算法"><a href="#AdaBoost算法" class="headerlink" title="AdaBoost算法"></a>AdaBoost算法</h3><p>AdaBoost（Adaptive Boosting，自适应增强），其自适应在于：前 一个基本分类器分错的样本会得到加强，加权后的全体样本再次被用来 训练下一个基本分类器。同时，在每一轮中加入一个新的弱分类器，直到达到某个预定的足够小的错误率或达到预先指定的最大迭代次数。 </p>
<p><strong>后一个模型的训练永远是在前一个模型的基础上完成！</strong></p>
<p><strong>算法思想</strong> </p>
<p>• 初始化训练样本的权值分布，每个样本具有相同权重； </p>
<p>• 训练弱分类器，如果样本分类正确，则在构造下一个训练集中，它的权值就会被降低；反之提高。用更新过的样本集去训练下一个分类器； </p>
<p>• 将所有弱分类组合成强分类器，各个弱分类器的训练过程结束后，加大分类误差率小的弱分类器的权重，降低分类误差率大的弱分类器的权重。</p>
<p><img src="/assets%5C1682883078606.png" alt="1682883078606"></p>
<p><img src="/assets%5C1682883092653.png" alt="1682883092653"></p>
<h3 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h3><p>XGBoost 是大规模并行 boosting tree 的工具， 它是目前最快最好的开源 boosting tree 工具包 ，比常见的工具包快 10 倍以上。XGBoost 和 GBDT 两者都是 boosting 方法，除了工程实现、解决问题上的一些差异外，最大的不同就是目标函数的定义。</p>
<p><img src="/assets%5C1682883272170.png" alt="1682883272170"></p>
<p><img src="/assets%5C1682883319146.png" alt="1682883319146"></p>
<p><img src="/assets%5C1682883377475.png" alt="1682883377475"></p>
<p><img src="/assets%5C1682883414736.png" alt="1682883414736"></p>
<p><img src="/assets%5C1682883446921.png" alt="1682883446921"></p>
<p><img src="/assets%5C1682883460482.png" alt="1682883460482"></p>
<p>XGBoost的分裂方式 </p>
<p>使用贪心方法，选增益（ 𝑔𝑎𝑖𝑛 ）最大的分裂方式 </p>
<p>贪心方法，众多𝑔𝑎𝑖𝑛中找到最大值做为最优分割节点（split point），因此模型会将所有样本按照（一阶梯度）从小到大排序，通过遍历，查看每个节点是否需要分割，计算复杂度是：决策树叶子节点数 – 1。</p>
<h3 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h3><p>LightGBM 由微软提出，主要用于解决 GDBT 在海量数据中遇到的问 </p>
<p>题，以便其可以更好更快地用于工业实践中，其相对 XGBoost 具有训练速度快、内存占用低的特点。 </p>
<p>LightGBM与XGBoost相比，主要有以下几个优势： </p>
<p>1）更快的训练速度 </p>
<p>2）更低的内存消耗 </p>
<p>3）更好的准确率 </p>
<p>4）分布式支持，可快速处理海量数据</p>
<p><strong>LightGBM 的主要改进</strong> </p>
<p>LightGBM与XGBoost相比，主要有以下几个改进： </p>
<p>• 基于梯度的单边采样算法（Gradient-based One-Side Sampling, GOSS）； </p>
<p>• 互斥特征捆绑算法（Exclusive Feature Bundling, EFB）； </p>
<p>• 直方图算法（ Histogram ）； </p>
<p>• 基于最大深度的 Leaf-wise 的垂直生长算法； LightGBM &#x3D; XGBoost + GOSS + EFB+ Histogram </p>
<p><strong>基于梯度的单边采样算法</strong>（Gradient-based One-Side Sampling, GOSS） </p>
<p>主要思想是通过对样本采样的方法来减少计算目标函数增益时候的复杂度。 </p>
<p>GOSS 算法保留了梯度大的样本，并对梯度小的样本进行随机抽样，为了不改变样本的数据分布，在计算增益时为梯度小的样本引入一个常数进行平衡。 </p>
<p><strong>如果一个样本的梯度很小，说明该样本的训练误差很小，或者说该样本已经得到了很好的训练(well-trained)。</strong></p>
<p><img src="/assets%5C1682883617979.png" alt="1682883617979"></p>
<p><img src="/assets%5C1682883640612.png" alt="1682883640612"></p>
<p><strong>互斥特征捆绑算法（Exclusive Feature Bundling, EFB）</strong> </p>
<p>高维特征往往是稀疏的，而且特征间可能是相互排斥的（如两个特征不同时取非零值），如果两个特征并不完全互斥（如只有一部分情况下是不同时取非零值） ，可以用互斥率表示互斥程度。EFB算法指出如果将一些特征进行融合绑定，则可以降低特征数量。 </p>
<p>论文给出特征合并算法，其关键在于原始特征能从合并的特征中分离出来。</p>
<p><img src="/assets%5C1682883706216.png" alt="1682883706216"></p>
<p><strong>直方图算法</strong></p>
<p>直方图算法的基本思想是将连续的特征离散化为𝑘个离散特征，同时构造一个宽度为𝑘的直方图用于统计信息（含有 𝑘 个 bin）。利用直方图算法我们无需遍历数据，只需要遍历 𝑘 个 bin 即可找到最佳分裂点。</p>
<p><img src="/assets%5C1682928842769.png" alt="1682928842769"></p>
<p><img src="/assets%5C1682928860785.png" alt="1682928860785"></p>
<p><strong>直方图加速</strong> </p>
<p>在构建叶节点的直方图时，我们还可以通过父节点的直方图与相邻叶节点的直方图相减的方式构建，从而减少了一半的计算量。即：<strong>一个叶子节点的直方图可以由它的父亲节点的直方图与其兄弟的直方图做差得到</strong>。如节点分裂成两个时，右边叶子节点的直方图等于其父节点的直方图减去左边 </p>
<p>叶子节点的直方图。从而大大减少构建直方图的计算量。</p>
<p><img src="/assets%5C1682929110883.png" alt="1682929110883"></p>
<p><img src="/assets%5C1682929131198.png" alt="1682929131198"></p>
<p><strong>基于最大深度的 Leaf-wise 的垂直生长算法</strong> </p>
<p><img src="/assets%5C1682929169693.png" alt="1682929169693"></p>
<h2 id="机器学习-支持向量机"><a href="#机器学习-支持向量机" class="headerlink" title="机器学习-支持向量机"></a>机器学习-支持向量机</h2><ol>
<li>支持向量概念<ul>
<li>软间隔、硬间隔、线性可分，等不同情况下的分类方法</li>
<li>核函数</li>
</ul>
</li>
<li><strong>支持向量机的求解</strong></li>
<li>线性不可分：将低维映射到高维，使得线性不可分的函数能够线性可分（核技巧）</li>
</ol>
<h3 id="支持向量机概述"><a href="#支持向量机概述" class="headerlink" title="支持向量机概述"></a>支持向量机概述</h3><p>支 持 向 量 机 （ Support Vector Machine, SVM ） 是 一 类 按 监 督 学 习 （ supervised learning）方式对数据进行二元分类的广义线性分类器（generalized linear classifier），其决策边界是对学习样本求解的最大边距超平面（maximum-margin hyperplane） 。 </p>
<p>与逻辑回归和神经网络相比，支持向量机，在学习复杂的非线性方程时提供了一种更为清晰，更加强大的方式。 </p>
<p><img src="/assets%5C1682929508688.png" alt="1682929508688"></p>
<h4 id="硬间隔、软间隔和非线性-SVM"><a href="#硬间隔、软间隔和非线性-SVM" class="headerlink" title="硬间隔、软间隔和非线性 SVM"></a>硬间隔、软间隔和非线性 SVM</h4><p><img src="/assets%5C1682929782332.png" alt="1682929782332"></p>
<h3 id="支持向量机求解"><a href="#支持向量机求解" class="headerlink" title="支持向量机求解"></a>支持向量机求解</h3><p><img src="/assets%5C1682929888771.png" alt="1682929888771"></p>
<p><img src="/assets%5C1682929907326.png" alt="1682929907326"></p>
<p><img src="/assets%5C1682929920706.png" alt="1682929920706"></p>
<p><img src="/assets%5C1682929939155.png" alt="1682929939155"></p>
<p><img src="/assets%5C1682929964521.png" alt="1682929964521"></p>
<h3 id="线性不可分支持向量机"><a href="#线性不可分支持向量机" class="headerlink" title="线性不可分支持向量机"></a>线性不可分支持向量机</h3><h4 id="核技巧"><a href="#核技巧" class="headerlink" title="核技巧"></a>核技巧</h4><p>在低维空间计算获得高维空间的计算结果，满足高维，才能在高维下线性可分。 我们需要引入一个新的概念：<strong>核函数。它可以将样本从原始空间映射到一个更高维的特质空间中，使得样本在新的空间中线性可分。</strong>这样我们就可以使用原来的推导来进行计算，只是所有的推导是在新的空间，而不是在原来的空间中进 行，即用核函数来替换当中的内积。 </p>
<p><img src="/assets%5C1682930072738.png" alt="1682930072738"></p>
<p><img src="/assets%5C1682930117888.png" alt="1682930117888"></p>
<p><img src="/assets%5C1682930143941.png" alt="1682930143941"></p>
<p>常用核函数有： </p>
<p>线性核函数</p>
<p><img src="/assets%5C1682930183582.png" alt="1682930183582"></p>
<p>多项式核函数 </p>
<p><img src="/assets%5C1682930196112.png" alt="1682930196112"></p>
<p>高斯核函数 </p>
<p><img src="/assets%5C1682930206595.png" alt="1682930206595"></p>
<p>这三个常用的核函数中,只有高斯核函数是需要调参的。</p>
<h2 id="机器学习-聚类"><a href="#机器学习-聚类" class="headerlink" title="机器学习-聚类"></a>机器学习-聚类</h2><p>K-means聚类</p>
<p>优点缺点：简答题</p>
<p>聚类的评价指标（轮廓系数）</p>
<h3 id="无监督学习方法概述"><a href="#无监督学习方法概述" class="headerlink" title="无监督学习方法概述"></a>无监督学习方法概述</h3><p>✓ 聚类（Clustering） </p>
<p>​	✓ 如何将教室里的学生按爱好、身高划分为5类？ </p>
<p>✓ 降维（ Dimensionality Reduction ） </p>
<p>​	✓ 如何将将原高维空间中的数据点映射到低维度的空间中？ </p>
<p>✓ 关联规则（ Association Rules） </p>
<p>​	✓ 很多买尿布的男顾客，同时买了啤酒，可以从中找出什么规律来提高超市销售额？ </p>
<p>✓ 推荐系统（ Recommender systems） </p>
<p>​	✓ 很多客户经常上网购物，根据他们的浏览商品的习惯，给他们推荐什么商品呢？</p>
<h3 id="K-means聚类"><a href="#K-means聚类" class="headerlink" title="K-means聚类"></a>K-means聚类</h3><h4 id="K-均值算法-K-means-算法概述"><a href="#K-均值算法-K-means-算法概述" class="headerlink" title="K-均值算法(K-means)算法概述"></a>K-均值算法(K-means)算法概述</h4><p>K-means算法是一种<strong>无监督学习</strong>方法，是最普及的聚类算法，算法使用一个<strong>没有标签</strong>的数据集，然后将数据聚类成不同的组。 </p>
<p>K-means算法具有一个迭代过程，在这个过程中，数据集被分组成若干个预定义的不重叠的聚类或子组，使簇的内部点尽可能相似，同时试图保 </p>
<p>持簇在不同的空间，它将数据点分配给簇，以便<strong>簇的质心和数据点之间的平方距离之和最小</strong>，在这个位置，簇的质心是簇中数据点的算术平均值。</p>
<h3 id="距离度量"><a href="#距离度量" class="headerlink" title="距离度量"></a>距离度量</h3><h4 id="闵可夫斯基距离-Minkowski-distance"><a href="#闵可夫斯基距离-Minkowski-distance" class="headerlink" title="闵可夫斯基距离(Minkowski distance)"></a><strong>闵可夫斯基距离(Minkowski distance)</strong></h4><p>𝑝取1或2时的闵氏距离是最为常用的 </p>
<p>𝑝 &#x3D; 2即为欧氏距离 </p>
<p>𝑝 &#x3D; 1时则为曼哈顿距离 </p>
<p>当𝑝取无穷时的极限情况下，可以得到切比雪夫距离 </p>
<p><img src="/assets%5C1683038285710.png" alt="1683038285710"></p>
<p><img src="/assets%5C1683038298601.png" alt="1683038298601"></p>
<h3 id="K-means算法流程"><a href="#K-means算法流程" class="headerlink" title="K-means算法流程"></a>K-means算法流程</h3><p>K-means算法流程 </p>
<ol>
<li>选择K个点作为初始质心。 </li>
<li>将每个点指派到最近的质心，形成K个簇。 </li>
<li>对于上一步聚类的结果，进行平均计算，得出该簇的新的聚类中心。 </li>
<li>重复上述两步&#x2F;直到迭代结束：质心不发生变化。</li>
</ol>
<p><img src="/assets%5C1683038344132.png" alt="1683038344132"></p>
<p>首先，初始化称为簇质心的任意点。初始化时，必须注意簇的质心必须小于训练数据点的数目。因为该算法是一种迭代算法，接下来的两个步骤是迭代执行的。</p>
<p><img src="/assets%5C1683038375526.png" alt="1683038375526"></p>
<p>初始化后，遍历所有数据点，计算所有质心与数据点之间的距离。现在，这些簇将根据 与质心的最小距离而形成。在本例中，数据分为3个簇(𝐾 &#x3D; 3)。 </p>
<p><img src="/assets%5C1683038477113.png" alt="1683038477113"></p>
<p>第三步：移动质心，因为上面步骤中形成的簇没有优化，所以需要形成优化的簇。为此，我们需要迭代地将质心移动到一个新位置。取一个簇的数据点，计算它们的平均值，然后将该簇的质心移动到这个新位置。对所有其他簇重复相同的步骤。 </p>
<p><img src="/assets%5C1683038510242.png" alt="1683038510242"></p>
<p><img src="/assets%5C1683038539836.png" alt="1683038539836"></p>
<p><img src="/assets%5C1683038572159.png" alt="1683038572159"></p>
<p><img src="/assets%5C1683038586557.png" alt="1683038586557"></p>
<h3 id="K-means的优点"><a href="#K-means的优点" class="headerlink" title="K-means的优点"></a>K-means的优点</h3><p>⚫ 原理比较简单，实现也是很容易，收敛速度快。 </p>
<p>⚫ 聚类效果较优。 </p>
<p>⚫ 算法的可解释度比较强。 </p>
<p>⚫ 主要需要调参的参数仅仅是簇数K。</p>
<h3 id="K-means的缺点"><a href="#K-means的缺点" class="headerlink" title="K-means的缺点"></a>K-means的缺点</h3><p>• 需要预先指定簇的数量； </p>
<p>• 如果有两个高度重叠的数据，那么它就不能被区分，也不能判断有两个簇； </p>
<p>• 欧几里德距离可以不平等的权重因素，限制了能处理的数据变量的类型； </p>
<p>• 有时随机选择质心并不能带来理想的结果； </p>
<p>• 无法处理异常值和噪声数据； </p>
<p>• 不适用于非线性数据集； </p>
<p>• 对特征尺度敏感； </p>
<p>• 如果遇到非常大的数据集，那么计算机可能会崩溃。</p>
<h3 id="聚类的评价指标"><a href="#聚类的评价指标" class="headerlink" title="聚类的评价指标"></a>聚类的评价指标</h3><p>(1) 均一性：𝑝 </p>
<p>类似于精确率，一个簇中只包含一个类别的样本，则满足均一性。其实也可以认为就是正确率(每个聚簇中正确分类的样本数占该聚簇总样本数的比例和) </p>
<p><img src="/assets%5C1683038788172.png" alt="1683038788172"></p>
<p>(2) 完整性：𝑟 </p>
<p>类似于召回率，同类别样本被归类到相同簇中，则满足完整性;(每个聚簇中正确分类的样本数占该类型的总样本数比例的和) </p>
<p><img src="/assets%5C1683038801431.png" alt="1683038801431"></p>
<p>(3) V-measure: </p>
<p>均一性和完整性的加权平均</p>
<p><img src="/assets%5C1683038822807.png" alt="1683038822807"></p>
<p><img src="/assets%5C1683038845703.png" alt="1683038845703"></p>
<p><img src="/assets%5C1683038863986.png" alt="1683038863986"></p>
<h2 id="机器学习-人工神经网络"><a href="#机器学习-人工神经网络" class="headerlink" title="机器学习-人工神经网络"></a>机器学习-人工神经网络</h2><p>BP算法：前向传播、反向传播</p>
<p><strong>第三节</strong>，关键就是BP算法</p>
<h3 id="BP算法"><a href="#BP算法" class="headerlink" title="BP算法"></a>BP算法</h3><p><img src="/assets%5C1683038981652.png" alt="1683038981652"></p>
<p><img src="/assets%5C1683038998968.png" alt="1683038998968"></p>
<p>最常用Sigmoid函数的<strong>优缺点</strong>： </p>
<p>优点： </p>
<p>1.函数处处连续，便于求导 </p>
<p>2.可将函数值的范围压缩至[0,1]，可用于压缩数据，且幅度不变 </p>
<p>3.便于前向传输 </p>
<p>缺点： </p>
<p>1.在趋向无穷的地方，函数值变化很小，容易出现梯度消失，不利于深层神经的反馈传输 </p>
<p>2.幂函数的梯度计算复杂 </p>
<p>3.收敛速度比较慢</p>
<h4 id="主要步骤"><a href="#主要步骤" class="headerlink" title="主要步骤"></a>主要步骤</h4><p>第一步，对样本明确预测输出值与损失函数 </p>
<p>第二步，明确参数调整策略 </p>
<p>第三步，计算输出层阈值的梯度 </p>
<p>第四步，计算隐层到输出层连接权值的梯度 </p>
<p>第五步，计算隐层阈值的梯度 </p>
<p>第六步，计算输入层到隐层连接权值的梯度 </p>
<p>第七步，引出归纳结论</p>
<p><img src="/assets%5C1683039040790.png" alt="1683039040790"></p>
<p><img src="/assets%5C1683039059299.png" alt="1683039059299"></p>
<p><img src="/assets%5C1683039079007.png" alt="1683039079007"></p>
<p><img src="/assets%5C1683039101323.png" alt="1683039101323"></p>
<p><img src="/assets%5C1683039127439.png" alt="1683039127439"></p>
<p><img src="/assets%5C1683039153432.png" alt="1683039153432"></p>
<p><img src="/assets%5C1683039169732.png" alt="1683039169732"></p>
<p>只要知道上一层神经元的阈值梯度，即可计算当前层神经元阈值梯度和连接权值梯度。 </p>
<p>随后可以计算输出层神经元阈值梯度，从而计算出全网络的神经元阈值和连接权值梯度。 </p>
<p>最终达到训练网络的目的。</p>
<p><img src="/assets%5C1683039203984.png" alt="1683039203984"></p>
<p><strong>优点：</strong> </p>
<p>1.能够自适应、自主学习。BP可以根据预设参数更新规则，通过不断调整神经网络中的参数，已达到最符合期望的输出。 </p>
<p>2.拥有很强的非线性映射能力。 </p>
<p>3.误差的反向传播采用的是成熟的链式法则，推导过程严谨且科学。 </p>
<p>4.算法泛化能力很强。 </p>
<p><strong>缺点：</strong> </p>
<p>1.BP神经网络参数众多，每次迭代需要更新较多数量的阈值和权值，故收敛速度比较慢。 </p>
<p>2.网络中隐层含有的节点数目没有明确的准则，需要不断设置节点数字试凑，根据网络误差结果最终确定隐层节点个数 </p>
<p>3.BP算法是一种速度较快的梯度下降算法，容易陷入局部极小值的问题。</p>

    </div>

       <div>
        
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------本文到这里结束了，感谢您的阅读------</div>
    
</div>

        
    </div>

    
    
    
        <div class="reward-container">
  <div><您的支持将是我继续创作的动力！></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechat.png" alt="君不见 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="君不见 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>君不见
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://decxlr.github.io/2023/05/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0/" title="机器学习复习">https://decxlr.github.io/2023/05/02/机器学习复习/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>


 

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Note/" rel="tag"><i class="fa fa-tag"></i> Note</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/05/01/Request%E4%B8%8EResponse%E5%AD%A6%E4%B9%A0/" rel="prev" title="Request与Response学习">
      <i class="fa fa-chevron-left"></i> Request与Response学习
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/05/11/JSP%E5%AD%A6%E4%B9%A0/" rel="next" title="JSP学习">
      JSP学习 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  




          </div>
          
    
  <div class="comments">
    <div id="SOHUCS"></div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>


      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%BC%95%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">机器学习-引言</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%B1%BB%E5%9E%8B-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.1.</span> <span class="nav-text">机器学习的类型-监督学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%B1%BB%E5%9E%8B-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.2.</span> <span class="nav-text">机器学习的类型-无监督学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%B1%BB%E5%9E%8B-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.3.</span> <span class="nav-text">机器学习的类型-强化学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%A6%82%E5%BF%B5-%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.4.</span> <span class="nav-text">机器学习的概念-模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%A6%82%E5%BF%B5-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">1.5.</span> <span class="nav-text">机器学习的概念-损失函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%9B%9E%E5%BD%92"><span class="nav-number">2.</span> <span class="nav-text">机器学习-回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95-LSM"><span class="nav-number">2.1.</span> <span class="nav-text">线性回归-最小二乘法(LSM)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%9A%84%E4%B8%89%E7%A7%8D%E5%BD%A2%E5%BC%8F"><span class="nav-number">2.2.</span> <span class="nav-text">梯度下降的三种形式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">2.2.1.</span> <span class="nav-text">批量梯度下降</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">2.2.2.</span> <span class="nav-text">随机梯度下降</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">2.2.3.</span> <span class="nav-text">小批量梯度下降</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B8%8E%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E6%AF%94%E8%BE%83"><span class="nav-number">2.3.</span> <span class="nav-text">梯度下降与最小二乘法比较</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">2.3.1.</span> <span class="nav-text">梯度下降</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95"><span class="nav-number">2.3.2.</span> <span class="nav-text">最小二乘法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%BD%92%E4%B8%80%E5%8C%96-x2F-%E6%A0%87%E5%87%86%E5%8C%96"><span class="nav-number">2.4.</span> <span class="nav-text">数据归一化&#x2F;标准化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8F%90%E5%8D%87%E6%A8%A1%E5%9E%8B%E7%B2%BE%E5%BA%A6"><span class="nav-number">2.4.1.</span> <span class="nav-text">提升模型精度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8A%A0%E9%80%9F%E6%A8%A1%E5%9E%8B%E6%94%B6%E6%95%9B"><span class="nav-number">2.4.2.</span> <span class="nav-text">加速模型收敛</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88"><span class="nav-number">2.5.</span> <span class="nav-text">过拟合和欠拟合</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E7%9A%84%E5%A4%84%E7%90%86"><span class="nav-number">2.5.1.</span> <span class="nav-text">过拟合的处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AC%A0%E6%8B%9F%E5%90%88%E7%9A%84%E5%A4%84%E7%90%86"><span class="nav-number">2.5.2.</span> <span class="nav-text">欠拟合的处理</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">2.6.</span> <span class="nav-text">正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%F0%9D%90%8B%F0%9D%9F%8F%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">2.6.1.</span> <span class="nav-text">𝐋𝟏正则化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%F0%9D%90%8B2%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">2.6.2.</span> <span class="nav-text">𝐋2正则化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96-1"><span class="nav-number">2.6.3.</span> <span class="nav-text">正则化</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="nav-number">3.</span> <span class="nav-text">机器学习-逻辑回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Sigmoid%E5%87%BD%E6%95%B0"><span class="nav-number">3.1.</span> <span class="nav-text">Sigmoid函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%B1%82%E8%A7%A3"><span class="nav-number">3.2.</span> <span class="nav-text">逻辑回归求解</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.1.</span> <span class="nav-text">损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.2.</span> <span class="nav-text">代价函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%B1%82%E8%A7%A3-1"><span class="nav-number">3.2.3.</span> <span class="nav-text">逻辑回归求解</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="nav-number">4.</span> <span class="nav-text">机器学习-朴素贝叶斯</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%8E%9F%E7%90%86"><span class="nav-number">4.1.</span> <span class="nav-text">朴素贝叶斯原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.1.1.</span> <span class="nav-text">判别模型和生成模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%8B%AC%E7%AB%8B%E6%80%A7"><span class="nav-number">4.1.2.</span> <span class="nav-text">独立性</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91"><span class="nav-number">5.</span> <span class="nav-text">机器学习-决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="nav-number">5.1.</span> <span class="nav-text">决策树</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E7%89%B9%E7%82%B9"><span class="nav-number">5.2.</span> <span class="nav-text">决策树的特点</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%98%E7%82%B9"><span class="nav-number">5.2.1.</span> <span class="nav-text">优点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%BA%E7%82%B9"><span class="nav-number">5.2.2.</span> <span class="nav-text">缺点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E4%B8%89%E7%A7%8D%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B"><span class="nav-number">5.3.</span> <span class="nav-text">决策树的三种基本类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ID3%E7%AE%97%E6%B3%95"><span class="nav-number">5.4.</span> <span class="nav-text">ID3算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%B6%E5%A4%A7%E8%87%B4%E6%AD%A5%E9%AA%A4%E4%B8%BA%EF%BC%9A"><span class="nav-number">5.4.1.</span> <span class="nav-text">其大致步骤为：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%A1%E6%81%AF%E7%86%B5"><span class="nav-number">5.4.2.</span> <span class="nav-text">信息熵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9D%A1%E4%BB%B6%E7%86%B5"><span class="nav-number">5.4.3.</span> <span class="nav-text">条件熵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%EF%BC%88%EF%BC%89"><span class="nav-number">5.4.4.</span> <span class="nav-text">信息增益（）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%BA%E7%82%B9-1"><span class="nav-number">5.4.5.</span> <span class="nav-text">缺点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#C4-5%E7%AE%97%E6%B3%95"><span class="nav-number">5.5.</span> <span class="nav-text">C4.5算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%8E%87%EF%BC%88%EF%BC%89"><span class="nav-number">5.5.1.</span> <span class="nav-text">信息增益率（）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#C4-5%E7%9A%84%E5%89%AA%E6%9E%9D"><span class="nav-number">5.5.2.</span> <span class="nav-text">C4.5的剪枝</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%A2%84%E5%89%AA%E6%9E%9D%EF%BC%88prepruning%EF%BC%89"><span class="nav-number">5.5.3.</span> <span class="nav-text">预剪枝（prepruning）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%8E%E5%89%AA%E6%9E%9D"><span class="nav-number">5.5.4.</span> <span class="nav-text">后剪枝</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#C4-5%E7%9A%84%E7%BC%BA%E7%82%B9"><span class="nav-number">5.5.5.</span> <span class="nav-text">C4.5的缺点</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0"><span class="nav-number">6.</span> <span class="nav-text">机器学习-集成学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0"><span class="nav-number">6.1.</span> <span class="nav-text">集成学习</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Bagging"><span class="nav-number">6.1.1.</span> <span class="nav-text">Bagging</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Boosting"><span class="nav-number">6.1.2.</span> <span class="nav-text">Boosting</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Stacking"><span class="nav-number">6.1.3.</span> <span class="nav-text">Stacking</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="nav-number">6.1.4.</span> <span class="nav-text">随机森林</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AdaBoost%E7%AE%97%E6%B3%95"><span class="nav-number">6.2.</span> <span class="nav-text">AdaBoost算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#XGBoost"><span class="nav-number">6.3.</span> <span class="nav-text">XGBoost</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LightGBM"><span class="nav-number">6.4.</span> <span class="nav-text">LightGBM</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="nav-number">7.</span> <span class="nav-text">机器学习-支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E6%A6%82%E8%BF%B0"><span class="nav-number">7.1.</span> <span class="nav-text">支持向量机概述</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A1%AC%E9%97%B4%E9%9A%94%E3%80%81%E8%BD%AF%E9%97%B4%E9%9A%94%E5%92%8C%E9%9D%9E%E7%BA%BF%E6%80%A7-SVM"><span class="nav-number">7.1.1.</span> <span class="nav-text">硬间隔、软间隔和非线性 SVM</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E6%B1%82%E8%A7%A3"><span class="nav-number">7.2.</span> <span class="nav-text">支持向量机求解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E4%B8%8D%E5%8F%AF%E5%88%86%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="nav-number">7.3.</span> <span class="nav-text">线性不可分支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A0%B8%E6%8A%80%E5%B7%A7"><span class="nav-number">7.3.1.</span> <span class="nav-text">核技巧</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%81%9A%E7%B1%BB"><span class="nav-number">8.</span> <span class="nav-text">机器学习-聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0"><span class="nav-number">8.1.</span> <span class="nav-text">无监督学习方法概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-means%E8%81%9A%E7%B1%BB"><span class="nav-number">8.2.</span> <span class="nav-text">K-means聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#K-%E5%9D%87%E5%80%BC%E7%AE%97%E6%B3%95-K-means-%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0"><span class="nav-number">8.2.1.</span> <span class="nav-text">K-均值算法(K-means)算法概述</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F"><span class="nav-number">8.3.</span> <span class="nav-text">距离度量</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%97%B5%E5%8F%AF%E5%A4%AB%E6%96%AF%E5%9F%BA%E8%B7%9D%E7%A6%BB-Minkowski-distance"><span class="nav-number">8.3.1.</span> <span class="nav-text">闵可夫斯基距离(Minkowski distance)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-means%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="nav-number">8.4.</span> <span class="nav-text">K-means算法流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-means%E7%9A%84%E4%BC%98%E7%82%B9"><span class="nav-number">8.5.</span> <span class="nav-text">K-means的优点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-means%E7%9A%84%E7%BC%BA%E7%82%B9"><span class="nav-number">8.6.</span> <span class="nav-text">K-means的缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%81%9A%E7%B1%BB%E7%9A%84%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="nav-number">8.7.</span> <span class="nav-text">聚类的评价指标</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">9.</span> <span class="nav-text">机器学习-人工神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#BP%E7%AE%97%E6%B3%95"><span class="nav-number">9.1.</span> <span class="nav-text">BP算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E6%AD%A5%E9%AA%A4"><span class="nav-number">9.1.1.</span> <span class="nav-text">主要步骤</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="君不见"
      src="/images/tsy.png">
  <p class="site-author-name" itemprop="name">君不见</p>
  <div class="site-description" itemprop="description">君不见，黄河之水天上来，奔流到海不复回。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">55</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/godx06" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;godx06" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/3451246424@qq.com" title="E-Mail → 3451246424@qq.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/7655616259/profile?rightmod=1&wvr=6&mod=personinfo&is_all=1" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;7655616259&#x2F;profile?rightmod&#x3D;1&amp;wvr&#x3D;6&amp;mod&#x3D;personinfo&amp;is_all&#x3D;1" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/m0_61465701?spm=1018.2226.3001.5343" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;m0_61465701?spm&#x3D;1018.2226.3001.5343" rel="noopener" target="_blank"><i class="fab fa-skype fa-fw"></i>CSDN</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://leetcode.cn/" title="https:&#x2F;&#x2F;leetcode.cn&#x2F;" rel="noopener" target="_blank">力扣</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.nowcoder.com/" title="https:&#x2F;&#x2F;www.nowcoder.com&#x2F;" rel="noopener" target="_blank">牛客</a>
        </li>
    </ul>
  </div>

      </div>

      <div id="music163player">
        <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=450 src="//music.163.com/outchain/player?type=0&id=8029840379&auto=0&height=66">
        </iframe>
      </div>
      
    </div>


  </aside>

    

  <div id="sidebar-dimmer"></div>




      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">君不见</span>
</div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_lines.min.js"></script>


  
  <script data-pjax>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="/js/local-search.js"></script>






  <script src="//code.tidio.co/qkwnepnheqrn9usrfqkth95hu196bfin.js"></script>







    <div id="pjax">
  

  
<script src="https://unpkg.com/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '64px',
  right: 'unset',
  left: '32px',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>

  <script>
  NexT.utils.loadComments(document.querySelector('#SOHUCS'), () => {
    var appid = 'cyw4nNoc5';
    var conf = '00d96ca2de6f5fc1a13903b7caf0a878';
    var width = window.innerWidth || document.documentElement.clientWidth;
    if (width < 960) {
      window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=' + appid + '&conf=' + conf + '"><\/script>');
    } else {
      var loadJs=function(d,a){var c=document.getElementsByTagName("head")[0]||document.head||document.documentElement;var b=document.createElement("script");b.setAttribute("type","text/javascript");b.setAttribute("charset","UTF-8");b.setAttribute("src",d);if(typeof a==="function"){if(window.attachEvent){b.onreadystatechange=function(){var e=b.readyState;if(e==="loaded"||e==="complete"){b.onreadystatechange=null;a()}}}else{b.onload=a}}c.appendChild(b)};loadJs("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:appid,conf:conf})});
    }
  });
  </script>
  <script src="https://assets.changyan.sohu.com/upload/plugins/plugins.count.js"></script>

    </div>




</body>
</html>
